services:
  fks_training:
    build:
      context: .
      dockerfile: shared/shared_docker/templates/python.gpu.Dockerfile
    working_dir: /app/src
    command: ["python", "-m", "main"]
    environment:
      TZ: America/Toronto
      SERVICE_PORT: 4400
      PYTHONPATH: /app/src
      CUDA_VISIBLE_DEVICES: all
    ports:
      - "4400:4400"
    volumes:
      - /etc/timezone:/etc/timezone:ro
      - /etc/localtime:/etc/localtime:ro
      - ./logs:/app/logs
      - ./models:/app/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    networks: [fks_net]
    healthcheck:
      test: ["CMD-SHELL", "python -c 'import torch; print(torch.cuda.is_available())' || exit 1"]
      interval: 120s
      timeout: 20s
      retries: 2
      start_period: 90s

networks:
  fks_net:
    name: fks_net