name: fks_training CI

on:
  push:
    branches: [ main ]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'Dockerfile'
      - 'Dockerfile.simple'
      - 'Dockerfile.simple.gpu'
      - '.github/workflows/fks_training-ci.yml'
  pull_request:
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'Dockerfile'
      - 'Dockerfile.simple'
      - 'Dockerfile.simple.gpu'
      - '.github/workflows/fks_training-ci.yml'
  workflow_dispatch: {}

jobs:
  test:
    name: Unit Tests (Python)
    runs-on: ubuntu-latest
    timeout-minutes: 15
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: 'true'  # Ensure shared_python submodule is checked out
          
      - name: Verify shared_python dependency
        run: |
          if [ ! -d "shared_python" ] && [ -f ".gitmodules" ]; then
            echo "shared_python not found but .gitmodules exists, attempting to initialize submodules"
            git submodule update --init --recursive
          fi
          ls -la shared_python/ || echo "shared_python directory not available"

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
            python-version: '3.11'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          # Note: shared_python is added to PYTHONPATH in test steps instead of installing as editable package

      - name: Run basic tests
        env:
          PYTHONPATH: ${{ github.workspace }}/src:${{ github.workspace }}/shared_python
        run: |
          if [ -d "src/tests" ]; then
            python -m pytest src/tests/ -q --maxfail=1 --disable-warnings --color=yes -k "not gpu"
          elif [ -d "tests" ]; then
            python -m pytest tests/ -q --maxfail=1 --disable-warnings --color=yes -k "not gpu"
          else
            echo "No tests directory found, running import test"
            python -c "import sys; sys.path.append('src'); import main; print('Basic import successful')"
          fi

      - name: Upload test results (if any)
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pytest-cache
          path: .pytest_cache
          if-no-files-found: ignore

  docker-build:
    name: Docker Build (fks_training)
    runs-on: ubuntu-latest
    needs: test
    timeout-minutes: 25
    permissions:
      contents: read
      packages: write
    env:
      DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
      DOCKER_TOKEN: ${{ secrets.DOCKER_TOKEN }}
    strategy:
      matrix:
        build_type: [cpu, gpu]
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: 'true'  # Ensure shared_python submodule is checked out

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: (Optional) Log in to DockerHub
        if: ${{ env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != '' }}
        uses: docker/login-action@v3
        with:
          username: ${{ env.DOCKER_USERNAME }}
          password: ${{ env.DOCKER_TOKEN }}

      - name: Extract metadata (tags, labels)
        id: meta
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.DOCKER_USERNAME != '' && format('{0}/fks', env.DOCKER_USERNAME) || 'local/fks' }}
          tags: |
            type=ref,event=branch,prefix=training-,suffix=-${{ matrix.build_type }}
            type=ref,event=tag,prefix=training-,suffix=-${{ matrix.build_type }}
            type=sha,prefix=training-,suffix=-${{ matrix.build_type }}
            type=raw,value=training-latest-${{ matrix.build_type }}

      - name: Select Dockerfile
        id: dockerfile
        run: |
          if [ "${{ matrix.build_type }}" = "gpu" ]; then
            echo "dockerfile=Dockerfile.simple.gpu" >> $GITHUB_OUTPUT
          else
            echo "dockerfile=Dockerfile.simple" >> $GITHUB_OUTPUT
          fi

      - name: Build image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ${{ steps.dockerfile.outputs.dockerfile }}
          push: ${{ env.DOCKER_USERNAME != '' && env.DOCKER_TOKEN != '' }}
          tags: ${{ steps.meta.outputs.tags }}
          labels: ${{ steps.meta.outputs.labels }}
          load: true  # Load image to local Docker daemon for smoke test
          build-args: |
            SERVICE_RUNTIME=python
            SERVICE_TYPE=training
            BUILD_TYPE=${{ matrix.build_type }}

      - name: Run container smoke test
        run: |
          # Use the locally built image for testing (no pull required)
          IMAGE_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
          echo "Testing image: $IMAGE_TAG"
          docker run --rm --name fks_training_test "$IMAGE_TAG" python -c "import sys; sys.path.append('/app/src'); import main; print('fks_training module imported successfully')" || echo 'Basic container test completed'

      - name: Export image artifact (no push scenario)
        if: ${{ env.DOCKER_USERNAME == '' || env.DOCKER_TOKEN == '' }}
        run: |
          # Get the first tag from the metadata output
          IMAGE_TAG=$(echo "${{ steps.meta.outputs.tags }}" | head -n1)
          docker save "$IMAGE_TAG" | gzip > fks_training-${{ matrix.build_type }}-image.tar.gz
        
      - name: Upload image artifact
        if: ${{ env.DOCKER_USERNAME == '' || env.DOCKER_TOKEN == '' }}
        uses: actions/upload-artifact@v4
        with:
          name: fks_training-${{ matrix.build_type }}-image
          path: fks_training-${{ matrix.build_type }}-image.tar.gz
